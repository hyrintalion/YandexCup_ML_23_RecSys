{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "340aceb6-4360-49ac-8381-bb42055d6146",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-23T14:18:38.577540Z",
     "start_time": "2023-10-23T14:18:17.212677Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32801790-6619-4141-b909-a70de5e00071",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-23T14:33:31.877048Z",
     "start_time": "2023-10-23T14:33:31.848465Z"
    }
   },
   "outputs": [],
   "source": [
    "CUDA_DEV = 0\n",
    "NUM_TAGS = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29f35090-eb3d-464b-b46f-de30c4d42d4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-23T14:33:32.347461Z",
     "start_time": "2023-10-23T14:33:32.237309Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b46b7d4b-785e-4187-b2bc-6c620c7b8cf1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-23T14:33:33.321337Z",
     "start_time": "2023-10-23T14:33:33.301510Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "track_idx2embeds = {}\n",
    "for fn in tqdm(glob('track_embeddings/*')):\n",
    "    track_idx = int(fn.split('/')[1].split('.')[0])\n",
    "    embeds = np.load(fn)\n",
    "    track_idx2embeds[track_idx] = embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d1b5cae-60ae-4584-a6bb-4f6b833929aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-23T14:33:36.194565Z",
     "start_time": "2023-10-23T14:33:36.172136Z"
    }
   },
   "outputs": [],
   "source": [
    "class TaggingDataset(Dataset):\n",
    "    def __init__(self, df, testing=False):\n",
    "        self.df = df\n",
    "        self.testing = testing\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        track_idx = row.track\n",
    "        embeds = track_idx2embeds[track_idx]\n",
    "        if self.testing:\n",
    "            return track_idx, embeds\n",
    "        tags = [int(x) for x in row.tags.split(',')]\n",
    "        target = np.zeros(NUM_TAGS)\n",
    "        target[tags] = 1\n",
    "        return track_idx, embeds, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca9ac5cf-a481-4918-bbeb-ecf077c681ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-23T14:33:36.781523Z",
     "start_time": "2023-10-23T14:33:36.760831Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = TaggingDataset(df_train)\n",
    "test_dataset = TaggingDataset(df_test, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31c659b7-ee4b-44da-a715-b7abced07279",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-23T14:33:39.930361Z",
     "start_time": "2023-10-23T14:33:39.919229Z"
    }
   },
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes = NUM_TAGS,\n",
    "        input_dim = 768,\n",
    "        hidden_dim = 512\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.bn = nn.LayerNorm(hidden_dim)\n",
    "        self.projector =  nn.Linear(input_dim, hidden_dim)\n",
    "        self.lin = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim)\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "        \n",
    "\n",
    "    def forward(self, embeds):\n",
    "        x = [self.projector(x) for x in embeds]\n",
    "        x = [v.mean(0).unsqueeze(0) for v in x]\n",
    "        x = self.bn(torch.cat(x, dim = 0))\n",
    "        x = self.lin(x)\n",
    "        outs = self.fc(x)\n",
    "        return outs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c70bf034-7966-4f44-9f2e-dcaf0f8a8184",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-23T14:33:41.840496Z",
     "start_time": "2023-10-23T14:33:41.808541Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss = None\n",
    "    alpha = 0.8\n",
    "    for iteration,data in enumerate(loader):\n",
    "        optimizer.zero_grad()\n",
    "        track_idxs, embeds, target = data\n",
    "        embeds = [x.to(CUDA_DEV) for x in embeds]\n",
    "        target = target.to(CUDA_DEV)\n",
    "        pred_logits = model(embeds)\n",
    "        pred_probs = torch.sigmoid(pred_logits)\n",
    "        ce_loss = criterion(pred_logits, target)\n",
    "        ce_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if running_loss is None:\n",
    "            running_loss = ce_loss.item()\n",
    "        else:\n",
    "            running_loss = alpha * ce_loss.item() + (1 - alpha) * ce_loss.item()\n",
    "        if iteration % 100 == 0:\n",
    "            print('   {} batch {} loss {}'.format(\n",
    "                datetime.now(), iteration + 1, running_loss\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e624b0b-8daf-4702-a5de-c667fcd53121",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-23T14:33:52.911444Z",
     "start_time": "2023-10-23T14:33:52.893996Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(model, loader):\n",
    "    model.eval()\n",
    "    track_idxs = []\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            track_idx, embeds = data\n",
    "            embeds = [x.to(CUDA_DEV) for x in embeds]\n",
    "            pred_logits = model(embeds)\n",
    "            pred_probs = torch.sigmoid(pred_logits)\n",
    "            predictions.append(pred_probs.cpu().numpy())\n",
    "            track_idxs.append(track_idx.numpy())\n",
    "    predictions = np.vstack(predictions)\n",
    "    track_idxs = np.vstack(track_idxs).ravel()\n",
    "    return track_idxs, predictions\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4decde5-005a-4820-804c-cf4d110c799e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-23T14:33:56.289379Z",
     "start_time": "2023-10-23T14:33:56.279597Z"
    }
   },
   "outputs": [],
   "source": [
    "def collate_fn(b):\n",
    "    track_idxs = torch.from_numpy(np.vstack([x[0] for x in b]))\n",
    "    embeds = [torch.from_numpy(x[1]) for x in b]\n",
    "    targets = np.vstack([x[2] for x in b])\n",
    "    targets = torch.from_numpy(targets)\n",
    "    return track_idxs, embeds, targets\n",
    "\n",
    "def collate_fn_test(b):\n",
    "    track_idxs = torch.from_numpy(np.vstack([x[0] for x in b]))\n",
    "    embeds = [torch.from_numpy(x[1]) for x in b]\n",
    "    return track_idxs, embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62124a85-3bcc-4eb8-a0d7-931c8685d1b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-23T14:33:57.339831Z",
     "start_time": "2023-10-23T14:33:57.328438Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False, collate_fn=collate_fn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "448ff0ee-2a61-4761-8d54-8b555bca7a09",
   "metadata": {
    "scrolled": true,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-10-23T14:33:58.551843Z",
     "start_time": "2023-10-23T14:33:58.312603Z"
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[23], line 5\u001B[0m\n\u001B[1;32m      2\u001B[0m criterion \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mBCEWithLogitsLoss()\n\u001B[1;32m      4\u001B[0m epochs \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m5\u001B[39m\n\u001B[0;32m----> 5\u001B[0m model \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mto(CUDA_DEV)\n\u001B[1;32m      6\u001B[0m criterion \u001B[38;5;241m=\u001B[39m criterion\u001B[38;5;241m.\u001B[39mto(CUDA_DEV)\n\u001B[1;32m      7\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mAdam(model\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3e-4\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1160\u001B[0m, in \u001B[0;36mModule.to\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1156\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mto(device, dtype \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1157\u001B[0m                     non_blocking, memory_format\u001B[38;5;241m=\u001B[39mconvert_to_format)\n\u001B[1;32m   1158\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mto(device, dtype \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, non_blocking)\n\u001B[0;32m-> 1160\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_apply(convert)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:810\u001B[0m, in \u001B[0;36mModule._apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    808\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[1;32m    809\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[0;32m--> 810\u001B[0m         module\u001B[38;5;241m.\u001B[39m_apply(fn)\n\u001B[1;32m    812\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[1;32m    813\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[1;32m    814\u001B[0m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[1;32m    815\u001B[0m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    820\u001B[0m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[1;32m    821\u001B[0m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:833\u001B[0m, in \u001B[0;36mModule._apply\u001B[0;34m(self, fn, recurse)\u001B[0m\n\u001B[1;32m    829\u001B[0m \u001B[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001B[39;00m\n\u001B[1;32m    830\u001B[0m \u001B[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001B[39;00m\n\u001B[1;32m    831\u001B[0m \u001B[38;5;66;03m# `with torch.no_grad():`\u001B[39;00m\n\u001B[1;32m    832\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m--> 833\u001B[0m     param_applied \u001B[38;5;241m=\u001B[39m fn(param)\n\u001B[1;32m    834\u001B[0m should_use_set_data \u001B[38;5;241m=\u001B[39m compute_should_use_set_data(param, param_applied)\n\u001B[1;32m    835\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m should_use_set_data:\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1158\u001B[0m, in \u001B[0;36mModule.to.<locals>.convert\u001B[0;34m(t)\u001B[0m\n\u001B[1;32m   1155\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m convert_to_format \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m t\u001B[38;5;241m.\u001B[39mdim() \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;241m4\u001B[39m, \u001B[38;5;241m5\u001B[39m):\n\u001B[1;32m   1156\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mto(device, dtype \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1157\u001B[0m                 non_blocking, memory_format\u001B[38;5;241m=\u001B[39mconvert_to_format)\n\u001B[0;32m-> 1158\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mto(device, dtype \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, non_blocking)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/cuda/__init__.py:289\u001B[0m, in \u001B[0;36m_lazy_init\u001B[0;34m()\u001B[0m\n\u001B[1;32m    284\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m    285\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    286\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmultiprocessing, you must use the \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mspawn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m start method\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    287\u001B[0m     )\n\u001B[1;32m    288\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(torch\u001B[38;5;241m.\u001B[39m_C, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_cuda_getDeviceCount\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m--> 289\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTorch not compiled with CUDA enabled\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    290\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _cudart \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    291\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\n\u001B[1;32m    292\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    293\u001B[0m     )\n",
      "\u001B[0;31mAssertionError\u001B[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "model = Network()\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "epochs = 5\n",
    "model = model.to(CUDA_DEV)\n",
    "criterion = criterion.to(CUDA_DEV)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    train_epoch(model, train_dataloader, criterion, optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a65faa1-76ff-4329-aadf-65594c8f577e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-23T14:18:40.143917Z"
    }
   },
   "outputs": [],
   "source": [
    "track_idxs, predictions = predict(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f38f54-5bdc-4b24-b711-83aa87f1f11f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-23T14:18:40.154580Z",
     "start_time": "2023-10-23T14:18:40.146226Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions_df = pd.DataFrame([\n",
    "    {'track': track, 'prediction': ','.join([str(p) for p in probs])}\n",
    "    for track, probs in zip(track_idxs, predictions)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810b0804-c39b-4cb3-9a00-fb443a8aa734",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-23T14:18:40.150433Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions_df.to_csv('prediction.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
